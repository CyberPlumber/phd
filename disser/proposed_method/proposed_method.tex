%!TEX root = ../dissertation.tex


\chapter{Proposed Method}
\label{method}


\section{Deterministic Forecasts}
\label{dmethod}

In theory, a perfect deterministic numerical forecast would consist of a perfect (in amplitude and phase) initialization and a perfect integration forward in time resulting in the correct forecast of what was observed. Unfortunately, the current state of our modeling systems is such that perfect forecasts are impossible. Numerical forecasts begin with errors in the initialization, use imperfect approximations of physical processes, and utilize discretized approximations of the continuous atmosphere, all of which result in errors in the final forecast.

This inherent uncertainty in numerical forecasts has led to the recognition that numerical forecasts should have a probabilistic component \citep{ADD}. For many years probabilistic guidance has been produced from deterministic forecasts in the United States using model output statistics (commonly referred to as MOS), a logistical regression process in which the likelihood of a specified outcome at a given location is estimated on the basis of past model performance \citep{Glahn1972}. Unfortunately, statistical post-processing of model output works best when modeling systems allow for the creation of a forecast sample that adequately represents the larger forecast population. In the case of operational numerical models this implies modeling systems must remain consistent for long periods of time. Calibration becomes more challenging with modeling systems that have been recently modified, which limits the forecast sample. Additional challenges arise when dealing with rare events, which require a long forecast sample to adequately represent the forecast population of rare events.

The statistical post-processing method proposed here goes beyond \cite{Theis2005} and \cite{Sobash2011} by employing a compositing and fitting technique for objective calibration of forecast probabilities. The idea behind the proposed method is to objectively determine where observations of a given event occur relative to forecasts of that event. This information is then used to fit an analytic function to the two-dimensional frequency histogram. Several analytic functions might be good candidates for this purpose; a two-dimensional Gaussian function is used here, fitted using methods similar to \cite{Lak2010}. In theory a normalized version of the raw two-dimensional frequency histogram, could be used, but, there is no guarantee that this would produce continuous forecast probabilities.




\subsection{2-D Compositing}
\label{compositing}

The compositing employed here is straight forward. First create a 0-filled, two-dimensional array of lengths $2m+1$ and $2n+1$.




\subsection{Mean Displacement Vector}
\label{displacement}

After creation of the two-dimensional frequency histogram, the next step involves determining the centroid of two-dimensional frequency histogram, and, in turn, determining the mean displacement vector. The centroid's location, represented by $\mu_x$ and $\mu_y$ can be computed using

    \begin{equation}
        \label{mux}
        \mu_x = \frac{1}{\mathbf{H}} \sum\limits_{j=-m \atop i=-n}^{n,m}H_{ij} \cdot i,
    \end{equation}

    \begin{equation}
        \label{muy}
        \mu_y = \frac{1}{\mathbf{H}} \sum\limits_{j=-m \atop i=-n}^{n,m}H_{ij} \cdot j,
    \end{equation}

\noindent where $H$ is the observed two-dimensional histogram, $n$ is half the length of the x-dimension of $H$, $m$ is half the length of the y-dimension, and

    \begin{equation}
        \mathbf{H} = \sum\limits_{i=-n \atop j=-m}^{n,m} H_{ij},
    \end{equation}

\noindent given that the forecast is found at $(0, 0)$. Thus, the observation mean displacement vector is simply $(\mu_x, \mu_y)$.




\subsection{Fitting a Distribution}
\label{fitting}

Once the mean displacement vector is known, the next step is to fit a statistical distribution to the two-dimensional




\subsection{Putting it All Together}
\label{kde}




\section{Extending to an Ensemble}
\label{emethod}
