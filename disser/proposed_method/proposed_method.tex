%!TEX root = ../dissertation.tex


\chapter{Proposed Method}
\label{method}


\section{Deterministic}
\label{dmethod}

In theory, a perfect deterministic numerical forecast would consist of a perfect (in amplitude and phase) initialization and a perfect integration forward in time resulting in the correct forecast of what was observed. Unfortunately, the current state of our modeling systems is such that perfect forecasts are impossible. Numerical forecasts begin with errors in the initialization, use imperfect approximations of physical processes, and utilize discretized approximations of the continous atmosphere, all of which result in errors in the final forecast.

This inherent uncertainty in numerical forecasts has led to the recognition that numerical forecasts should have a probabilistic component \citep{ADD}. For many years probabilistic guidance has been produced from deterministic forecasts in the United States using model output statistics (commonly referred to as MOS), a logistical regressioin process in which the likelihood of a specified outcome at a given location is estimated on the basis of past model performance \citep{Glahn1972}. Unfortunately, statistical post-processing of model output works best when modeling systems allow for the creation of a forecast sample that adequately represents the larger forecast population. In the case of operational numerical models this implies modeling systems must remain consistent for long periods of time. Calibration becomes more challenging with modeling systems that have been recently modified, which limits the forecast sample. Additional challenges arise when dealing with rare events, which require a long forecast smaple to adequately represent the forecast population of rare events.

The statistical post-processing method proposed here goes beyond \cite{Theis2005} and \cite{Sobash2011} by employing a compositing and fitting technique for objective calibration of forecast probabilities. The idea behind the proposed method is to objectively determine where observations of a given event fall relative to forecasts of that event. This information can then be used to calculate the mean displacement overall variance of observations relative to forecasts. This first step, compositing, determines a two-dimensional spatial histogram of observations of a phenomenon relative to forecasts of the phenomenon. Once this two-dimensional spatial histogram is known, the mean displacement can be calculated. This is simply the vector from the forecast location to the centroid of the observed two-dimensional frequency histogram. Next, a two-dimensional statistical distribution is then fit to the spatial histogram. Several analysic functions might be good candidates for this purpose, but a two-dimensional Gaussian function is used here, fitted using methods similar to \cite{Lak2010}.

Once the mean displacement vector and the fitted distribution are known, every grid point forecast of the event can be shifted by the mean displacement vector. Each shifted forecast (and the new neighboring grid points) is then replaced with the fitted distribution. The final probabilistic forecast is simply a linear combination of all the grid point by grid point probabilistic forecasts, similar to methods employed by kernel density estimation \citep{KDE}. This is explained further in section \ref{kde}.




\section{Ensemble}
\label{emethod}
