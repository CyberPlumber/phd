%!TEX root = ../dissertation.tex


\section{Ensemble Data}
\label{edata}




\subsection{Ensemble Forecasts}
\label{emodel}

As discussed at the beginning of \mbox{chapter \ref{deterministic}}, in order to develop a statistical post-processing method for calibration of numerical weather prediction forecasts, both forecasts and observations must be readily available.
Unfortunately, as mentioned in the Introduction, ``\dots there is a limited database of forecasts for RCEs, making robust statistical techniques difficult\dots''
As limited as databases of deterministic CAM forecasts are, the availability of ensembles of CAM forecasts is even worse.


Similar to CAM forecasts, most storm-scale ensemble forecast systems\footnote{The phrase storm-scale ensemble forecast is typically used in reference to ensembles composed of numerical forecasts produced without using cumulus parameterization.} (SSEF) have been short-term initiatives, produced in support of various field programs and experiments.
The makeup of these SSEFs are often modified year-to-year to adapt to the changing needs of the various field programs and experiments.
This makes finding a long running, consistent ensemble extremely difficult.


One of the largest collections of SSEF forecasts has been produced by the University of Oklahoma's Center for the Analysis and Prediction of Storms (CAPS).
Since 2007, CAPS has been producing CAM forecasts in support of the Hazardous Weather Testbed's (HWT) annual Spring Forecast Experiment (SFE).
From 2007 through 2010, the ensemble configuration changed from year-to-year based on the results of previous years.
In 2010, CAPS produced a 26 member SSEF.
This SSEF was multi-model in nature, initialized at 00 UTC, used 4 km grid spacing, and integrated out to 30 hours.
Of the 26 members, 19 were WRF-ARW\footnote{Weather Research and Forecasting -- Advanced Research WRF} \citep{WRFV3}, 5 were WRF-NMM\footnote{Weather Research and Forecasting -- nonhydrostatic Mesoscale Model} \citep{NAMnWRF-NMM}, and 2 were ARPS\footnote{Advanced Regional Prediction System} \citep{ARPS}.
In 2011, CAPS expanded the SSEF from 26 members to 50, of which 41 were WRF-ARW, 5 were WRF-NMM, and 4 were ARPS.
These forecasts were also initialized at 00 UTC, used a grid spacing of 4 km, but were integrated forward to 36 hours instead of 30.


From these 26 members in 2010 and 50 members in 2011, 15 were chosen to be held as consistent as possible between the two years.
These 15 members were composed of 10 WRF-ARW forecasts, 4 WRF-NMM forecasts, and 1 ARPS forecast.
The background initial conditions for these 15 members were downscaled from the 00 UTC 12 km NAM, with additional information coming from a three dimensional variational and cloud analysis from ARPS.
Except for the control members (one each from the WRF-ARW, WRF-NMM, and ARPS), these initial conditions were then perturbed using mesoscale atmospheric perturbations from NOAA's Environmental Modeling Center's operational Short-Range Ensemble Forecast (SREF) system.
Lateral boundary conditions for the three control members came from the 00 UTC NAM's forecasts, whereas the remaining 12 members used the SREF forecast corresponding to the perturbations used in the initial conditions.
A listing of the configurations for each member of the SSEF can be found in \mbox{Table \ref{ensemble_members}}.


The only controlled change between 2010 and 2011 for the aforementioned set of 15 forecasts came from a change in the version of WRF. In 2010, \mbox{WRF Version 3.1.1} was used whereas \mbox{WRF Version 3.2.1} was used in 2011.
Changes in the NAM and SREF, which were used for initial and lateral boundary conditions, were controlled by the NOAA National Weather Service and could not be avoided.


In 2010 the HWT SFE ran from 17 May through 18 June, and in 2011, the HWT SFE ran from 09  May through 10 June.
CAPS provided SSEF forecasts each weekday during the experiment, with an additional two retrospective forecasts in 2011: one for the 27 April 2011 tornado outbreak in the southeast United States and another for the 22 May 2011 Joplin, Missouri EF-5 tornado.
\mbox{Table \ref{sfedtes}} lists the exact dates CAPS forecasts are available.


In an effort to be consistent with the evaluation carried out on the NSSL-WRF, the decision was made to use six-hour accumulation periods for both SSEF forecasts\footnote{Unless otherwise noted, from this point forward the phrase ``SSEF'', ``SSEF forecasts'', or variants thereof refer to the 15 numerical forecasts that are presented in \mbox{Table \ref{ensemble_members}}.} and the Stage IV analyses.
The SSEF forecasts were drawn from the \mbox{12-36 hr} forecasts ending at 18, 00, 06, and 12 UTC, but only for \mbox{6 hr} time periods for which every member was available.
This means that out of the 208 possible \mbox{6 hr} time periods (52 days times 4 periods a day), the potential dataset was immediately reduced to 156 six-hour time periods (52 days times 3 periods a day) because the 2010 SSEF was only integrated out to \mbox{30 hr}.




\subsection{Observations}
\label{eobservations}

As was the case for the evaluating the deterministic model calibration, NCEP's Stage IV national quantitative precipitation estimate analysis was chosen as the verification dataset.
Please see \mbox{section \ref{observations}} for a description of the Stage IV dataset.




\subsection{Processing}
\label{eprocessing}

As stated in \mbox{section \ref{emodel}}, there were a maximum of 156 six-hour time periods for which SSEF data was expected.
This potential dataset was further thinned by removing all time periods in which either one or more SSEF members were missing or the Stage IV analysis was unavailable.
An additional 37 six-hour time periods were removed as a result, leaving 119 six-hour time periods, over 2010 and 2011, for which both the entire SSEF and the Stage IV analyses are available.


Next, as was necessary with the deterministic forecasts, the ensemble forecasts were interpolated to the Stage IV grid.
All diagnostics and analyses were conducted on this grid.
Furthermore, the same mask shown in \mbox{Figure \ref{domain}} was used to limit the analyses to areas east of the Rocky Mountains and near land.


Unfortunately, 119 time periods is a very small sample from which to evaluate a method for statical calibration of forecasts of rare events.
This is especially true when the training and forecast data must both come from the 119 time periods.
For comparison, the NSSL-WRF training dataset had 4120 training time periods and 1425 forecast time periods.
In an attempt to maximize the utility of the 119 time periods the evaluation was only conducted using the \mbox{12.7 mm} in \mbox{6 hr} threshold.


In addition to only using the lower threshold, twenty ``simulations'' were created by resampling the 119 time periods.
This was accomplished by randomly drawing, without replacement, 59 training periods from the valid 119 time periods with the remaining 60 periods used as forecast periods.
From these 59 training periods, two-dimensional histograms were created for each of the 15 ensemble members.
These histograms were then used to calculate the five fitting parameters --- $\sigma_x$, $\sigma_y$, $\theta$, $h$, and $k$ --- for each member's unique two-dimensional anisotropic Gaussian function.
Forecasts for each member were then made for each time period of the 60 forecast time periods, with each member using their own fitted anisotropic Gaussian function.
Thus, for each simulation all 15 ensemble members used the same 59 time periods for training and the remaining 60 time periods for forecasting.
This results in 18 000 forecasts (20 simulations x 60 forecast periods x 15 members).






