{
 "metadata": {
  "name": "create_forecasts_ssef"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "import os\n",
      "import sys\n",
      "import time\n",
      "import shutil\n",
      "import datetime\n",
      "from glob import glob\n",
      "import cPickle as pickle\n",
      "from random import choice\n",
      "\n",
      "import numpy as np\n",
      "from scipy import ndimage\n",
      "\n",
      "import hwt\n",
      "import metpy as mp\n",
      "import disser; reload(disser)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('Platform: {0.platform}\\nPython Version: {0.version}'.format(sys))\n",
      "print('Numpy Version: {0}'.format(np.__version__))\n",
      "print('HWT Version: {0}'.format(hwt.__version__))\n",
      "print('Disser Version: {0}'.format(disser.__version__))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "-----\n",
      "# Create SSEF Forecasts\n",
      " "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rc = Client()\n",
      "%px import os\n",
      "%px import numpy as np\n",
      "%px import disser\n",
      "view = rc.load_balanced_view()    # Load-Balanced View\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dx = 4.7\n",
      "factor = 5\n",
      "radius = 300\n",
      "thresh = 25.4 * 0.5\n",
      "number_of_simulations = 20\n",
      "\n",
      "stg4_root = r'/raid/efp/se2011/pmarsh/stg4/06h'\n",
      "ssef_root = r'/raid/efp/se2011/pmarsh/ssef_precip'\n",
      "npbin_root = r'/raid/efp/se2012/pmarsh/phd/ssef/%03ikm/2dhists/%05.2f/06h' % (radius, thresh)\n",
      "npbin_fcst_root = r'/raid/efp/se2012/pmarsh/phd/ssef/%03ikm/forecasts/%05.2f/06h/simulations' % (radius, thresh)\n",
      "\n",
      "pickle_file = os.path.join(npbin_fcst_root, r'simulation_config_%03ikm_%05.2f.pkl' % (radius, thresh))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Get a list of valid dates and times for each member of the ensemble. To be a valid date for a given member, both a stage4 and forecast file must be present"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ens_mem_dates = {}\n",
      "for member in disser.misc.se2010_members:\n",
      "    npbin_path = os.path.join(npbin_root, member)\n",
      "    ffiles = glob(os.path.join(npbin_path, '2010/*.npz')) + glob(os.path.join(npbin_path, '2011/*.npz'))\n",
      "    ffiles.sort()\n",
      "    dts = []\n",
      "    for f in ffiles:\n",
      "        dts.append(datetime.datetime.strptime(os.path.basename(f).split('.')[0], '%Y%m%d%H'))\n",
      "    ens_mem_dates[member] = dts\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, get a list of the dates that are in common amongst all ensemble members"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "valid_dts = []\n",
      "non_valid_dts = []\n",
      "for member in ens_mem_dates:\n",
      "    dts = ens_mem_dates[member]\n",
      "    for dt in dts:\n",
      "        if dt not in valid_dts:\n",
      "            mems = 0\n",
      "            for member in ens_mem_dates:\n",
      "                if dt in ens_mem_dates[member]:\n",
      "                    mems += 1\n",
      "            if mems == 15:\n",
      "                valid_dts.append(dt)\n",
      "            else:\n",
      "                non_valid_dts.append(dt)\n",
      "non_valid_dts = list(set(non_valid_dts))\n",
      "non_valid_dts.sort()\n",
      "print('Valid Dataset Size:', len(valid_dts))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, here's where we begin to set up our simulation parameters. For each simulation:\n",
      "\n",
      "+ Randomly select dates for the training period\n",
      "+ Then create a list of unused dates from which to verify the parameters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "simulation_config = {}\n",
      "simulation_config['number_of_simulations'] = number_of_simulations\n",
      "simulation_config['simulations'] = {}\n",
      "simulation_config['thresh'] = thresh\n",
      "simulation_config['radius'] = radius\n",
      "\n",
      "for sim in range(1, number_of_simulations+1):\n",
      "    unique_dates = len(valid_dts)\n",
      "    len_of_training = int(unique_dates / 2)\n",
      "    poss_inds = range(unique_dates)\n",
      "    chosen_dates = []\n",
      "    for i in range(len_of_training):\n",
      "        ind = poss_inds.pop(poss_inds.index(choice(poss_inds)))\n",
      "        chosen_dates.append(valid_dts[ind])\n",
      "    fcst_dates = [dt for dt in valid_dts if dt not in chosen_dates]\n",
      "    chosen_dates.sort()\n",
      "    fcst_dates.sort()\n",
      "    simulation_config['simulations'][sim] = {'training_dates': chosen_dates, \n",
      "                                             'forecast_dates': fcst_dates}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for key in simulation_config['simulations']:\n",
      "    train_length = len(simulation_config['simulations'][key]['training_dates'])\n",
      "    verif_length = len(simulation_config['simulations'][key]['forecast_dates'])\n",
      "    print('Simulation #:', key, '\\tTraining Size:', train_length, '\\tVerification Size:', verif_length)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, create a listing of all the files needed for each simulation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for sim in range(1, number_of_simulations+1):\n",
      "    initial = True\n",
      "    sfiles = []\n",
      "    for member in disser.misc.se2010_members:\n",
      "        ffiles = []\n",
      "        nfiles = []\n",
      "        for dt in fcst_dates:\n",
      "            yrmo = dt.strftime('%Y/%m')\n",
      "            year = dt.strftime('%Y')\n",
      "            date4 = dt.strftime('%Y%m%d')\n",
      "            fdate4 = (dt - datetime.timedelta(days=1)).strftime('%Y%m%d')\n",
      "            if initial:\n",
      "                # Set Stage4 File\n",
      "                stg4_path = os.path.join(stg4_root, yrmo)\n",
      "                sfiles.append(os.path.join(stg4_path, 'ST4.%s%02i.06h' % (date4, dt.hour)))\n",
      "            # Set SSEF File\n",
      "            if dt.hour <= 12:\n",
      "                date2 = (dt - datetime.timedelta(days=1)).strftime('%y%m%d')\n",
      "                ssef_path = os.path.join(ssef_root, os.path.join(date2, member))\n",
      "                ffiles.append(os.path.join(ssef_path, '%s.%sf%02i.06h' % (member, fdate4, dt.hour+24)))\n",
      "            else:\n",
      "                date2 = dt.strftime('%y%m%d')\n",
      "                ssef_path = os.path.join(ssef_root, os.path.join(date2, member))\n",
      "                ffiles.append(os.path.join(ssef_path, '%s.%sf%02i.06h' % (member, date4, dt.hour)))\n",
      "            # Set OUT File\n",
      "            npbin_fcst_path = os.path.join(npbin_fcst_root, os.path.join('%03i' % (sim), member))\n",
      "            nfiles.append(os.path.join(npbin_fcst_path, '%s%02i.npz' % (date4, dt.hour)))\n",
      "            if os.path.isdir(npbin_fcst_path):\n",
      "                shutil.rmtree(npbin_fcst_path)\n",
      "            os.makedirs(npbin_fcst_path)\n",
      "        initial = False\n",
      "        simulation_config['simulations'][sim][member] = {'fcst_files': ffiles, 'nout_files': nfiles}\n",
      "    simulation_config['simulations'][sim]['stg4_files'] = sfiles"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save \"simulation_config\" as a pickle object"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle.dump(simulation_config, open(pickle_file, \"wb\"), protocol=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we need to compute the fitted 2D-Gaussian for each member and each simulation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cmds = []\n",
      "for i in range(1, number_of_simulations+1):\n",
      "    kwargs = {'dts': simulation_config['simulations'][i]['training_dates'],\n",
      "              'sim_number': i, 'npbin_root': npbin_root, \n",
      "              'members': disser.misc.se2010_members}\n",
      "    cmds.append(kwargs)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jobs = view.map(disser.calibration.hist.get_simulation_params, cmds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "disser.misc.mpi_progress(view, jobs, len(cmds), 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This part parses the return fields from the parallel run, takes the parameters from the fitting and inserts them into the simulation parameter dictionary\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output = jobs.r\n",
      "output.sort()\n",
      "\n",
      "for sim_number, parameters in output:\n",
      "    for member in parameters:\n",
      "        for key in parameters[member]:\n",
      "            simulation_config['simulations'][sim_number][member][key] = parameters[member][key]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Dump this pickle file out for saving. For safety, this code block is set up to prevent automatic running. **DO NOT UNDO THIS!!!**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run = False\n",
      "if run:\n",
      "    pickle.dump(simulation_config, open(pickle_file, \"wb\"), protocol=2)\n",
      "    print('This was run!')\n",
      "else:\n",
      "    print('This was skipped!')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now create the SSEF Forecasts..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    simulation_config\n",
      "except:\n",
      "    simulation_config = pickle.load(open(pickle_file, 'rb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cmds = []\n",
      "members = disser.misc.se2010_members\n",
      "for i in range(1, number_of_simulations+1):\n",
      "    for member in members:\n",
      "        kwargs = {'stg4_files': simulation_config['simulations'][i]['stg4_files'], \n",
      "                  'fcst_files': simulation_config['simulations'][i][member]['fcst_files'], \n",
      "                  'nout_files': simulation_config['simulations'][i][member]['nout_files'], \n",
      "                  'sigx': simulation_config['simulations'][i][member]['sigx'], \n",
      "                  'sigy': simulation_config['simulations'][i][member]['sigy'], \n",
      "                  'xrot': simulation_config['simulations'][i][member]['xrot'], \n",
      "                  'h': simulation_config['simulations'][i][member]['ih'], \n",
      "                  'k': simulation_config['simulations'][i][member]['ik'],\n",
      "                  'dx': dx, 'fcst_thresh': thresh, 'factor': factor,\n",
      "                  'stg4_thresh': thresh, 'mask': disser.mask}\n",
      "        cmds.append(kwargs)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jobs = view.map(disser.calibration.create_forecasts, cmds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "disser.misc.mpi_progress(view, jobs, len(cmds), 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}